{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A taste of MLJ\n",
    "\n",
    "### Baby steps\n",
    "\n",
    "Let's load a reduced version of the well-known Ames House Price data set (containing six of the more important categorical features and six of the more important numerical features). We'll extract the data from one of the built-in [tasks](https://alan-turing-institute.github.io/MLJ.jl/dev/working_with_tasks/) (not discussed in this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "\n",
    "using MLJ\n",
    "using DataFrames, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>OverallQual</th><th>GrLivArea</th><th>Neighborhood</th><th>x1stFlrSF</th><th>TotalBsmtSF</th><th>BsmtFinSF1</th><th>LotArea</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Categorical…</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>4 rows × 12 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>5.0</td><td>816.0</td><td>Mitchel</td><td>816.0</td><td>816.0</td><td>816.0</td><td>6600.0</td></tr><tr><th>2</th><td>8.0</td><td>2028.0</td><td>Timber</td><td>2028.0</td><td>1868.0</td><td>1460.0</td><td>11443.0</td></tr><tr><th>3</th><td>7.0</td><td>1509.0</td><td>Gilbert</td><td>807.0</td><td>783.0</td><td>0.0</td><td>7875.0</td></tr><tr><th>4</th><td>6.0</td><td>1686.0</td><td>NWAmes</td><td>1686.0</td><td>1686.0</td><td>625.0</td><td>10240.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& OverallQual & GrLivArea & Neighborhood & x1stFlrSF & TotalBsmtSF & BsmtFinSF1 & LotArea & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Categorical… & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 5.0 & 816.0 & Mitchel & 816.0 & 816.0 & 816.0 & 6600.0 & $\\dots$ \\\\\n",
       "\t2 & 8.0 & 2028.0 & Timber & 2028.0 & 1868.0 & 1460.0 & 11443.0 & $\\dots$ \\\\\n",
       "\t3 & 7.0 & 1509.0 & Gilbert & 807.0 & 783.0 & 0.0 & 7875.0 & $\\dots$ \\\\\n",
       "\t4 & 6.0 & 1686.0 & NWAmes & 1686.0 & 1686.0 & 625.0 & 10240.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4×12 DataFrame. Omitted printing of 7 columns\n",
       "│ Row │ OverallQual │ GrLivArea │ Neighborhood │ x1stFlrSF │ TotalBsmtSF │\n",
       "│     │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mCategorical…\u001b[39m │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼─────────────┼───────────┼──────────────┼───────────┼─────────────┤\n",
       "│ 1   │ 5.0         │ 816.0     │ Mitchel      │ 816.0     │ 816.0       │\n",
       "│ 2   │ 8.0         │ 2028.0    │ Timber       │ 2028.0    │ 1868.0      │\n",
       "│ 3   │ 7.0         │ 1509.0    │ Gilbert      │ 807.0     │ 783.0       │\n",
       "│ 4   │ 6.0         │ 1686.0    │ NWAmes       │ 1686.0    │ 1686.0      │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = load_reduced_ames()\n",
    "X, y = task()\n",
    "\n",
    "train, test = partition(eachindex(y), 0.70, shuffle=true); # 70:30 split\n",
    "\n",
    "first(X, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *model* is a container for hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstantRegressor(distribution_type = Distributions.Normal,)\u001b[34m @ 1…45\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_model = ConstantRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping the model in data creates a *machine* which will store training outcomes (called *fit-results*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ConstantRegressor} @ 1…85\u001b[39m\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = machine(constant_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and making a new prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ConstantRegressor} @ 1…85\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/machines.jl:102\n",
      "┌ Info: Fitted a constant probability distribution, Distributions.Normal{Float64}(μ=179790.87340529932, σ=76344.53307783141).\n",
      "└ @ MLJ.Constant /Users/anthony/.julia/packages/MLJ/w0rRg/src/builtins/Constant.jl:45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Distributions.Normal{Float64},1}:\n",
       " Distributions.Normal{Float64}(μ=179790.87340529932, σ=76344.53307783141)\n",
       " Distributions.Normal{Float64}(μ=179790.87340529932, σ=76344.53307783141)\n",
       " Distributions.Normal{Float64}(μ=179790.87340529932, σ=76344.53307783141)\n",
       " Distributions.Normal{Float64}(μ=179790.87340529932, σ=76344.53307783141)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(constant, rows=train)\n",
    "yhat = predict(constant, X[test,:]);\n",
    "yhat[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we chose can provide probabilistic predictions and so does so by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 179790.87340529932\n",
       " 179790.87340529932\n",
       " 179790.87340529932\n",
       " 179790.87340529932"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.(yhat)[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4012495878729087"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsl(yhat, y[test]) # applies root-mean-square-log loss to prediction means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we could have skipped the train/test definitions and evaluated one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Evaluating using a holdout set. \n",
      "│ fraction_train=0.7 \n",
      "│ shuffle=false \n",
      "│ measure=MLJ.rmsl \n",
      "│ operation=StatsBase.predict \n",
      "│ Resampling from all rows. \n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/resampling.jl:91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4095126492179508"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(constant, resampling=Holdout(fraction_train=0.7), measure=rmsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something fancier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a composite model type that:\n",
    "\n",
    "- one-hot encodes the inputs\n",
    "- log transforms the target\n",
    "- fits specified K-nearest neighbour and ridge regressor models to the data\n",
    "- computes a weighted average of individual model predictions\n",
    "- inverse transforms (exponentiates) the blended predictions\n",
    "\n",
    "MLJ will eventually have macros for quickly building this kind of composite model (and more sophisticated model stacks). Nevertheless, building the model with our bare hands is easier than in other popular frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: A model named \"RidgeRegressor\" is already loaded.\n",
      "│ Nothing new loaded. \n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/loading.jl:163\n",
      "┌ Info: A model named \"KNNRegressor\" is already loaded.\n",
      "│ Nothing new loaded. \n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/loading.jl:163\n"
     ]
    }
   ],
   "source": [
    "@load RidgeRegressor \n",
    "@load KNNRegressor\n",
    "\n",
    "# the new model struture, with other models as hyperparameters:\n",
    "mutable struct KNNRidgeBlend <:DeterministicNetwork\n",
    "    knn_model\n",
    "    ridge_model\n",
    "    weight # between 0 and 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `DeterministicNetwork` means that our model will make determinisitic (as opposed to probabilistic) predictions, and that its `fit` method returns a node in an MLJ *learning network*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting instructions:\n",
    "function MLJ.fit(model::KNNRidgeBlend, X, y)\n",
    "    \n",
    "    # source nodes of the \"learning network\" being wrappped:    \n",
    "    \n",
    "    Xs = source(X) \n",
    "    ys = source(y)\n",
    "\n",
    "    hot = machine(OneHotEncoder(), Xs)\n",
    "\n",
    "    # W, z, zhat and yhat are nodes in the network:\n",
    "    \n",
    "    W = transform(hot, Xs) # one-hot encode the input\n",
    "    z = log(ys) # transform the target\n",
    "    \n",
    "    ridge_model = model.ridge_model\n",
    "    knn_model = model.knn_model\n",
    "\n",
    "    ridge = machine(ridge_model, W, z) \n",
    "    knn = machine(knn_model, W, z)\n",
    "\n",
    "    zhat = model.weight*predict(ridge, W) + (1 - model.weight)*predict(knn, W) # average the predictions of KNN and ridge models\n",
    "    yhat = exp(zhat) # inverse the target transformation\n",
    "    \n",
    "    fit!(yhat, verbosity=0)\n",
    "    \n",
    "    return yhat\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate a blended model and evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Evaluating using a holdout set. \n",
      "│ fraction_train=0.7 \n",
      "│ shuffle=false \n",
      "│ measure=MLJ.rmsl \n",
      "│ operation=StatsBase.predict \n",
      "│ Resampling from all rows. \n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/resampling.jl:91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13108966715886725"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNNRegressor(K=2)\n",
    "ridge_model = RidgeRegressor(lambda=0.1)\n",
    "knn_ridge_blend_model = KNNRidgeBlend(knn_model, ridge_model, 0.90)\n",
    "knn_ridge_blend = machine(knn_ridge_blend_model, X, y)\n",
    "er = evaluate!(knn_ridge_blend, resampling=Holdout(fraction_train=0.7), measure=rmsl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the nested hyperparameters of our composite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(knn_model = (K = 2,\n",
       "              metric = MLJ.KNN.euclidean,\n",
       "              kernel = MLJ.KNN.reciprocal,),\n",
       " ridge_model = (lambda = 0.1,),\n",
       " weight = 0.9,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(knn_ridge_blend_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next trick, we wrap the model in a tuning strategy, producing a new tuned model. \n",
    "\n",
    "The form of `nested_ranges` below matches the pattern above (with parameters not being tuned omitted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJ.DeterministicTunedModel(model = \u001b[34mKNNRidgeBlend{} @ 7…41\u001b[39m,\n",
       "                            tuning = \u001b[34mGrid{} @ 1…80\u001b[39m,\n",
       "                            resampling = \u001b[34mCV{} @ 2…56\u001b[39m,\n",
       "                            measure = MLJ.rmsl,\n",
       "                            operation = StatsBase.predict,\n",
       "                            nested_ranges = (knn_model = (K = \u001b[34mNumericRange{K} @ 1…07\u001b[39m,), ridge_model = (lambda = \u001b[34mNumericRange{lambda} @ 1…94\u001b[39m,)),\n",
       "                            minimize = true,\n",
       "                            full_report = true,)\u001b[34m @ 1…97\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_range = range(knn_model, :K, lower=2, upper=100, scale=:log10)\n",
    "lambda_range = range(ridge_model, :lambda, lower= 1e-6, upper=10, scale = :log10)\n",
    "\n",
    "nested_ranges = (knn_model = (K = K_range,), ridge_model = (lambda = lambda_range,))\n",
    "\n",
    "tuning = Grid(resolution=12)\n",
    "resampling = CV(nfolds=6)\n",
    "\n",
    "tuned_blended_model = TunedModel(model=knn_ridge_blend_model, \n",
    "    tuning=tuning, resampling=resampling, nested_ranges=nested_ranges, measure=rmsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a corresponding machine searches for the model with optimal performance, as determined by the specified tuning/resampling strategy, and trains the best model on all specifed data (in this case on `train`). So, predictions of the fitted machine are predictions using optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DeterministicTunedModel} @ 1…10\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/machines.jl:102\n",
      "\u001b[33mIterating over a 144-point grid: 100%[=========================] Time: 0:00:39\u001b[39m\n",
      "┌ Info: Training best model on all supplied data.\n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/tuning.jl:179\n"
     ]
    }
   ],
   "source": [
    "tuned_blended = machine(tuned_blended_model, X, y)\n",
    "fit!(tuned_blended, rows=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mKNNRidgeBlend{} @ 1…61\u001b[39m,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(tuned_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(best_model.knn_model).K = 2\n",
      "(best_model.ridge_model).lambda = 2.3101297000831598\n"
     ]
    }
   ],
   "source": [
    "best_model = ans.best_model\n",
    "@show best_model.knn_model.K;\n",
    "@show best_model.ridge_model.lambda;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Evaluating using a holdout set. \n",
      "│ fraction_train=0.7 \n",
      "│ shuffle=false \n",
      "│ measure=MLJ.rmsl \n",
      "│ operation=StatsBase.predict \n",
      "│ Resampling from all rows. \n",
      "└ @ MLJ /Users/anthony/.julia/packages/MLJ/w0rRg/src/resampling.jl:91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13067575064806702"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = machine(best_model, X, y)\n",
    "evaluate!(best, resampling=Holdout(fraction_train=0.7), measure=rmsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
